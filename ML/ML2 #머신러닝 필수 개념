1. 지도학습과 비지도학습
학습이란 데이터를 특별한 알고리즘에 적용해 머신러닝 모델을 정의된 문제에 최적화하는 과정을 의미한다.

1.1 지도학습
지도학습(supervised learning)이란 정답을 알려주면서 진행되는 학습이다.
따라서 학습 시 데이터와 함께 레이블(정답)이 항상 제공돼야 한다.
지도학습을 공부하다 보면 정답, 실제값, 타깃, 클래스, y값이라는 단어가 많이 혼용되지만 다 같은 의미이다.
주로 주어진 데이터와 레이블을 이용해 새로운 데이터의 레이블을 예측해야 할 때 사용된다.
머신러닝 모델을 통해 예측된 값을 예측값, 분류값, y hat 등으로 많이 표현된다.
테스트할 때는 데이터와 함께 레이블을 제공해서 손쉽게 모델의 성능을 평가할 수 있다는 장점이 있다.
하지만 데이터마다 레이블을 달기 위해 많은 시간을 투자해야 한다는 단점도 있다.
지도학습의 예로는 분류와 회귀가 대표적이다.

1.2 비지도학습
비지도학습(unsupervised learning)이란 레이블(정답)없이 진행되는 학습이다.
따라서 학습할 때 레이블 없이 데이터만 필요하다.
보통 데이터 자체에서 패턴을 찾아내야 할 때 사용된다.
레이블이 없기 때문에 모델 성능을 평가하는 데에는 다소 어려움이 있다.
하지만 따로 레이블을 제공할 필요가 없다는 장점이 있다.
비지도학습의 대표적인 예로는 군집화와 차원축소가 있다.

2. 분류와 회귀
분류(classification)와 회귀(regression)의 가장 큰 차이점은 데이터가 입력됐을 때 분류는 분리된 값으로 예측하고, 회귀는 연속된 값으로 예측한다는 데 있습니다. 
날씨로 예를 들면, 분류는 덥다,춥다와 같이 분리된 값으로 예측하는 반면 회귀는 30.5도, 3.5도와 같이 연속된 수치값으로 예측한다.

2.1 분류
분류는 데이터가 입력됐을 때 지도학습을 통해 미리 학습된 레이블 중 하나 또는 여러 개의 레이블로 예측하는 것이다.

- 이진분류
(예, 아니오), (남자, 여자)와 같이 둘 중 하나의 값으로 분류하는 경우 이진분류라고 부른다.
- 다중분류
(빨강, 녹색, 파랑) 중 하나의 색으로 분류하거나, 0부터 9까지의 손글씨 숫자 중 하나의 숫자로 분류하기처럼 여러 개의 분류값 중에서 하나의 값으로 예측하는 문제를 다중분류라고 부른다.
- 다중 레이블 분류
데이터가 입력됐을 때 두 개 이상의 레이블로 분류할 경우 다중 레이블 분류라고 합니다.
예를 들어, 분류값으로 세모, 네모, 동그라미가 있을 경우 아래와 같은 그림(동그라미, 세모)이 입력값으로 들어오면 다중 레이블 분류 모델의 예측값은 (동그라미, 세모)가 되고, 다중 분류 모델일 경우 세모와 네모 중 더 높은 확률을 지닌 레이블로 예측하게 된다.


2.2 회귀
회귀는 입력된 데이터에 대해 연속된 값으로 예측한다.
예를 들어, 날씨를 더움, 보통, 추움이라는 3가지로만 예측하는 분류와 달리, 회귀는 35도, 34.5도, 34도와 같이 정해진 레이블이 아닌 연속성을 가진 수치로 예측한다.


3. 과대적합과 과소적합
머신러닝 모델 학습에 가장 큰 영향을 주는 것은 데이터이다.
데이터에서 충분히 특성을 찾아내지 못하고 머신러닝 모델을 학습할 경우 모델이 과소적합(underfitting)되기 쉽고, 필요 이상의 특징으로 학습할 경우 모델이 과대적합(overfittin)되기 쉽다.

수학적으로 데이터에서 특징을 필요 이상으로 추출할 경우 분산(variance)이 높아지고, 반대로 필요 이하로 추출할 경우 편향(bias)이 높아진다.
에러율이 가장 적은 모델, 즉 최적의 모델은 분산과 편향이 균형된 모델이다.

3.1 과소적합
과소적합은 모델 학습 시 충분한 데이터의 특징을 활용하지 못할 경우 발생한다.
아래 예시는 과소적합 학습 데이터의 예이다.
---------------------------------------------------------------
사물                분류값                생김새
야구공              공                    동그라미
농구공              공                    동그라미
테니스공            공                    동그라미
딸기                과일                  세모
포도알              과일                  동그라미
---------------------------------------------------------------
사물을 보고 공을 구분하는 머신러닝 모델을 만들 때 위 학습 데이터를 사용할 경우 어떤 문제가 발생할까?
데이터의 특징으로는 생김새밖에 없으므로 생김새가 동그라미이면 공이라는 간단한 머신러닝 분류기를 만들 수 있다.
하지만 이 분류기는 학습 데이터에 대해서도 높은 정확도를 가지지 못한다.
이유는 공을 구별할 수 있는 특징이 너무 적기 때문에 현재 가지고 있는 데이터에 대해서도 정확도가 낮게 측정되는 것이며, 앞으로 다가올 실제 데이터에 대해서도 높은 정확도를 예상하기 어렵다.
이처럼 충분하지 못한 특징만으로 학습되어 특정 특징에만 편향되게 학습된 모델을 과소적합된 모델이라고 부르며, 보통 테스트 데이터뿐만 아니라 학습 데이터에 대해서도 정확도가 낮게 나올 경우 과소적합된 모델일 가능성이 높다.

3.2 과대적합
학습 데이터에서 필요 이상으로 특징을 발견해서 학습 데이터에 대한 정확도는 상당히 높지만 테스트 데이터 또는 학습 데이터 외의 데이터에는 정확도가 낮게 나오는 모델을 과대적합된 모델이라 부른다.
아래 예시는 과대적합의 예제이다.
-------------------------------------------------------------
사물        분류값        생김새        크기        줄무늬
야구공      공            원형          중간        있음
농구공      공            원형          큼          있음
테니스공    공            원형          중간        있음
딸기        과일          세모          중간        없음
포도알      과일          원형          작음        없음
-------------------------------------------------------------
위 특징 모두를 사용해서 머신러닝 모델을 학습할 경우 "생김새가 원형이고 크기가 작지 않으며, 줄무늬가 있으면 공이다"라는 명제를 가진 머신러닝 모델이 만들어질 수 있다.
이 머신러닝 모델은 현재 가지고 있는 학습 데이터에는 100%의 정확도를 보여주지만 학습 데이터에 포합되지 않은 아래의 테스트 데이터에는 0%의 정확도를 갖느다.

-------------------------------------------------------------
사물        분류값        생김새        크기        줄무늬
골프공      공            원형          작음        없음
수박        과일          원형          큼          있음
당구공      공            원형          중간        없음
럭비공      공            타원형        큼          있음
볼링공      공            원형          큼          없음
-------------------------------------------------------------
이처럼 머신러닝 모델이 학습 데이터에는 높은 정확도를 가지나 테스트 데이터 또는 실제 데이터에 대해서는 낮은 정확도를 보일 경우 과대적합을 의심할 수 있다.
과대적합은 특징이 필요 이상으로 많을 경우(분산이 높을 경우) 일어난다.

과대적합을 피하기 위해 가장 좋은 방법 중 간단하면서도 확실한 답은 더 많은 데이터를 확보해서 부족한 학습 데이터를 충분히 채우는 것이다.
하지만 데이터가 충분하지 않고 모델이 과대적합됐을 경우 학습에 사용된 특징을 줄여보는 것도 좋은 방법이다.
또한 특징들의 수치값을 정규화함으로써 특정 특징에 의한 편향을 줄이는 것도 과대적합을 피하는 좋은 방법 중 하나이다.

이 밖에도 딥러닝 같은 경우 조기 종료(early stopping) 및 드롭아웃(drop out)을 사용해 과대적합을 피할 수 있다.

4. 혼동 행렬
혼동 행렬(confusion matrix)은 모델의 성능을 평가할 때 사용되는 지표이다.
아래 알파벳을 보여줬을 때 알파벳을 알아맞히는 머신러닝 모델의 혼동행렬을 보자.
종으로 나열된 A,B,C,D는 입력된 데이터의 실제값이고, 횡으로 나열된 A,B,C,D는 예측값이다.

--------------------------------------------------------------------------
                           예측값
                A        B        C        D
        A       9        1        0        0
        B       1        15       3        1
실제값  C       5        0        24       1
        D       0        4        1        15

--------------------------------------------------------------------------

A : 10번 A를 보여줬을 경우, 9번은 A로 정확하게 맞췄으나, 1번은 B라고 대답함.
B : 20번 B를 보여줬을 경우, 15번은 B로 맞췄으나, 1번은 A, 3번은 C, 1번은 D라고 대답함.
C : 30번 C를 보여줬을 경우, 24번은 C로 맞췄으나, 5번은 A, 1번은 D라고 대답함.
D : 20번 D를 보여줬을 경우, 15번은 D로 맞췄으나, 4번은 B, 1번은 C라고 대답함.

혼동행렬을 통해 모델이 다소 B를 C로 혼동하는 것과, C를 A로 혼동한다는 것, D를 B로 혼동한다는 정보를 알아낼 수 있고 그에 따른 모델 개선을 생각해볼 수 있다.
또한 대략적인 모델의 성능도 눈으로 확인할 수 있다. 모델의 성능은 바로 이 혼동행렬을 기반으로 단 하나의 수치로 표현될 수 있다.

5. 머신러닝 모델의 성능 평가
모델을 성능을 평가하기 위해 혼동행렬과 함께 필요한 네 가지 개념이 있다.

5.1 TP(true positive) - 맞은 것을 올바르게 예측한 것
데이터를 입력했을 때 데이터의 실제값을 올바르게 예측한 케이스를 TP라고 한다.
아래 혼동 행렬의 대각선 부분은 TP이다.
--------------------------------------------------------------------------
                           예측값
                A        B        C        D
        A      (9)       1        0        0
        B       1       (15)      3        1
실제값  C       5        0       (24)      1
        D       0        4        1       (15)

--------------------------------------------------------------------------

5.2 TN(true negative) - 틀린 것을 올바르게 예측한 것
틀린 것을 올바르게 예측한 것을 TN이라고 한다.
A클래스의 TN은 A가 아닌 클래스들을 A가 아니라고 예측한 모든 값이다.
아래 혼동행렬에 ()로 되어있는 셀들이 바로 A클래스의 TN이다.
--------------------------------------------------------------------------
                           예측값
                A        B        C        D
        A       9        1        0        0
        B       1       (15)     (3)      (1)
실제값  C       5       (0)      (24)     (1)
        D       0       (4)      (1)      (15)

--------------------------------------------------------------------------
각 클래스별로 TN이 따로 존재한다. 예를 들어, D클래스의 TN은 아래의 혼동행렬에 ()로 표시한 셀들이다.
--------------------------------------------------------------------------
                           예측값
                A        B        C        D
        A      (9)      (1)      (0)       0
        B      (1)      (15)     (3)       1
실제값  C      (5)      (0)      (24)      1
        D       0        4        1        15

--------------------------------------------------------------------------

5.3 FP(false positive) - 틀린 것을 맞다고 잘못 예측한 것
틀린 것을 맞다고 잘못 예측한 것을 FP라고 한다. 
A클래스로 예를 들면, A가 아닌 B, C, D가 실체값인 데이터들을 입력했을 때, A라고 잘못 예측한 값들을 A클래스의 FP이다.
--------------------------------------------------------------------------
                           예측값
                A        B        C        D
        A       9        1        0        0
        B      (1)       15       3        1
실제값  C      (5)       0        24       1
        D      (0)       4        1        15

--------------------------------------------------------------------------

B클래스의 FP는 아래 혼동행렬의 예제로 확인할 수 있다.
--------------------------------------------------------------------------
                           예측값
                A        B        C        D
        A       9       (1)       0        0
        B       1        15       3        1
실제값  C       5       (0)       24       1
        D       0       (4)       1        15

--------------------------------------------------------------------------

5.4 FN(false negative) - 맞는 것을 틀렸다고 잘못 예측한 것
맞는 것을 틀렸다고 잘못 예측한 것을 FN이라고 한다.
A클래스로 예를 들면, A라는 실제값인 데이터를 입력했을 때 A가 아니라고 예측한 모든 케이스를 FN이라고 한다.
--------------------------------------------------------------------------
                           예측값
                A        B        C        D
        A       9       (1)      (0)      (0)
        B       1        15       3        1
실제값  C       5        0        24       1
        D       0        4        1        15

--------------------------------------------------------------------------

5.5 정확도
정확도(Accuracy)는 가장 일반적인 모델 성능 평가 지표이다.
모델이 입력된 데이터에 대해 얼마나 정확하게 예측하는지를 나타낸다.
혼동행렬 상에서는 대각선(TP)을 전체 셀로 나눈 값에 해당한다.
--------------------------------------------------------------------------
                           예측값
                A        B        C        D
        A      (9)       1        0        0
        B       1       (15)      3        1
실제값  C       5        0       (24)      1
        D       0        4        1       (15)

--------------------------------------------------------------------------

정확도 = 9 + 15 + 24 + 15 / 80 = 0.78
위 모델의 정확도는 0.78임을 확인할 수 있습니다.

5.6 정밀도
정밀도(percision)는 모델의 예측값이 얼마나 정확하게 예측됐는가를 나타내는 지표이다.
아래 표는 암 예측 모델 A의 혼동행렬이다.
----------------------------------------------------------------------------
                암환자                일반환자
암환자          9                     1
일반환자        30                    60
----------------------------------------------------------------------------
아래 표는 암 예측 모델 B의 혼동행렬이다.
----------------------------------------------------------------------------
                암환자                일반환자
암환자          1                     9
일반환자        20                    70
----------------------------------------------------------------------------

암 예측 모델 A, B 중 어떤 모델이 더 나은 모델일까
정확도를 비교하면 A모델이 69%, B모델이 71%이므로 B모델이 더 나은 암 예측 모델이라고 할 수 있을까?
사람들은 암 증상이 있어서 병원을 방문할 경우 암이라는 진단(예측)을 받았을 때 진단이 더 정확한 병원에 방문할 것이다.
이처럼 예측값이 얼마나 정확한가를 나타내는 지표가 바로 정밀도이다.

정밀도 = TP/(TP+FP)

모델 A의 암환자 정밀도 9/39 = 23%, 모델 B의 암환자 정밀도는 1/21 = 4.7%이므로, 암 환자 정밀도 기준으로 더 나은 모델은 모델 A이다.

5.7 재현율
재현율(Recall)은 실제값 중에서 모델이 검출한 실제값의 비율을 나타내는 지표이다.

재현율 = TP/(TP+FN)

다시 암환자를 예측하는 모델 A, B를 비교해 본다.
실제 암환자들이 병원에 갔을 때 암환자라고 예측될 확률을 구하는 것이 바로 재현율이고, 암환자를 조기에 정확하게 발견해서 신속하게 처방하는 것이 병원 입장에서도 올바른 모델 선택 방법이다.

모델A의 암환자 재현율은 9/10 = 90, 모델B의 암환자 재현율은 1/10 = 10%이므로 암환자 재현율을 기준으로 더 나은 모델은 A이다.

5.8 F1 점수
정밀도도 중요하고 재현율도 중요한데 둘 중 무엇을 쓸지 고민될 수 있다.
이 두 값을 조화평균 내서 하나의 수치로 나타낸 지표를 F1 점수(F1 Score)라고 한다.

F1점수 = 2 * 재현율 * 정밀도 / (재현율 + 정밀도)
정밀도,재현율의 값이 상이하게 차이나도 F1점수는 두 값의 조화평균 값을 주므로 F1점수는 정확도와 함께 성능 평가에 많이 사용된다.

보통 테스트 데이터의 레이블이 균일하게 분포돼 있을 때는 주로 정확도를 사용한다.
--------------------------------------------------------------------------
                           예측값
                A        B        C        D
        A      (9)       5        0        0
        B       1       (8)       1        0
실제값  C       2        0       (7)       1
        D       0        0        1       (9)

--------------------------------------------------------------------------
정확도 = (9+8+7+9) / 40 = 82.5%

하지만 데이터의 레이블이 불균일하게 분포돼 있을 경우 정확도는 왜곡된 성능 평가로 이어질 수 있다.
아래의 모델1은 A레이블만 잘 맞추고 B,C,D레이블에 대해 하나도 예측을 제대로 하지 못했음에도 A레이블을 가진 데이터가 너무 많아서 정확도가 96.6%로 나타나게 되어 성능 평가가 상당히 높아지는 문제를 잘 보여준다.
--------------------------------------------------------------------------
모델1                      예측값
                A        B        C        D
        A      (995)     5        0        0
        B       8       (0)       1        1
실제값  C       10       0       (0)       1
        D       0        1        9       (0)
--------------------------------------------------------------------------
정확도 = (995+0+0+0) / 1030 = 96.9%

심지어 아래의 모델 2는 A에 대한 예측율은 떨어지지만 보편적으로 예측을 상당히 잘하는 모델임에도 정확도는 위의 모델보다 낮게 평가된다.
--------------------------------------------------------------------------
모델2                      예측값
                A        B        C        D
        A      (700)    100      100      100
        B       0       (9)       1        0
실제값  C       0        0       (9)       1
        D       0        1        0       (9)
--------------------------------------------------------------------------
정확도 = (700+9+9+9) / 1030 = 70.5%

위와 같이 레이블이 데이터 상에서 불균일하게 분포된 경우 F1 점수를 사용하면 정확도보다 나은 성능 평가 비교가 가능하다.

아래의 모델1의 F1점수는 0.246으로 계산된다.
--------------------------------------------------------------------------
모델1                      예측값                재현율
                A        B        C        D     0.99
        A      (995)     5        0        0     0
        B       8       (0)       1        1     0
실제값  C       10       0       (0)       1     0
        D       0        1        9       (0)
정밀도         0.98      0        0        0
--------------------------------------------------------------------------
평균 정밀도 = (0.98 + 0 + 0 + 0) / 4 = 0.245
평균 재현율 = (0.99 + 0 + 0 + 0) / 4 = 0.2475
        F1 점수 = 2 * 0.245 * 0.2475 / (0.245 + 0.2475)
                = 0.121275 / 0.4925
                = 0.246

아래의 모델2의 F1점수는 0.454로 계산된다.
--------------------------------------------------------------------------
모델2                      예측값               재현율
                A        B        C        D    0.7
        A      (700)    100      100      100   0.9
        B       0       (9)       1        0    0.9
실제값  C       0        0       (9)       1    0.9
        D       0        1        0       (9)
정밀도          1       0.08     0.08     0.08 
--------------------------------------------------------------------------
평균 정밀도 = (1 + 0.08 + 0.08 + 0.08) / 4 = 0.31
평균 재현율 = (0.7 + 0.9 + 0.9 + 0.9) / 4 = 0.85
        F1 점수 = 2 * 0.31 * 0.85 / (0.31 + 0.85)
                = 0.527 / 1.16
                = 0.454

모델2가 F1점수를 기준으로 성능 평가 시 더 나은 점수를 얻는 것을 확인할 수 있다. 
이처럼 테스트에 사용되는 데이터가 불행하게도 레이블이 불균일하게 분포된 경우 F1점수는 한쪽 레이블에 치우치지 않는 레이블의 전체적인 성능에 대해 올바르게 평가하는 것을 확인 할 수 있다.

6. k-폴드 교차 검증
머신러닝 모델을 테스트하기 전에 검증 단계를 통해 대략적인 모델의 성능을 짐작해 볼 수 있다.
보편적으로 하나의 데이터셋이 있을 경우 전체 데이터셋의 20%를 테스트 데이터로 활용하고, 나머지 데이터의 90%를 학습 데이터로, 그리고 10%를 검증 데이터로 많이 사용하며, 이 방법은 현재도 많이 쓰이고 있다.
하지만 데이터가 충분하지 않을 경우 10%의 데이터를 검증 데이터로 나누기도 아깝고, 또한 나눈다 할지라도 검증 정확도를 신뢰하기에는 너무 한쪽에 편중된 데이터라는 단점이 있다.
이러한 문제를 극복하고자 고안된 검증 방법이 k-폴드(k-fold)교차 검증이다.

테스트 데이터를 나눈 후의 데이터를 학습 데이터라고 한다면 학습 데이터의 일정 부분을 검증 데이터로 쓰되,
n번의 검증 과정을 통해 학습 데이터의 모든 데이터를 한 번씩 검증 데이터로 사용해서 n개의 검증 결과를 평균낸 값을 검증 성능 평가 지표로 사용하는 방식이다.

교차 검증의 장점은 첫 번째로 검증 결과가 일정 데이터에 치우치지 않고 모든 데이터에 대한 결과이므로 신빙성이 높고,
두 번째로 따로 검증 데이터를 분리하지 않아도 된다는 점이다.

최종 검증 적확도 = 1차 검증 정확도 + 2차 검증 정확도 + ... + 10차 검증 정확도 / 10 이다.

k-폴드 교차 검증은 모든 학습 데이터를 한 번씩 검증 데이터로 활용해 검증 데이터가 한쪽 데이터에 편향돼 있지 않아 따로 검증 데이터를 분리하지 않고도 학습 데이터에 대한 전반적인검증 정확도를 구할 수 있다.
