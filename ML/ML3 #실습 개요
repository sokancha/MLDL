머신러닝 알고리즘 실습 개요

1. 알고리즘 선정 이유
머신러닝은 수집된 데이터와 특정 알고리즘을 기반으로 최적의 추론을 구하는 컴퓨터 프로그램이다.
최적의 추론을 구하기 위해 다양한 알고리즘들이 사용될 수 있다.

'어떤 알고리즘을 선정할까?'라는 질문에 '이 알고리즘을 쓰면 된다'라고 바로 답할 수 있는 최고의 알고리즘은 존재하지 않는다.
수집된 데이터의 특징과 상황에 따라 가장 적합한 알고리즘을 선택하는 것이 중요하다.

가령 수집된 데이터에 특징만 알고 분류값이 따로 설정돼 있지 않을 경우 지도학습 알고리즘은 사용할 수 없다.
이 경우 비지도학습 알고리즘인 k평균 군집화 알고리즘을 사용해 서로 유사한 데이터를 군집화할 수 있다.

수집된 데이터에 특징과 분류값이 모두 존재한다면 지도학습 알고리즘 중 가장 적합한 알고리즘을 찾아야한다.
가령 스마트폰 음성 비서같은 경우 추론의 정확도도 중요하지만 추론을 내기까지 걸리는 알고리즘의 시간 복잡도 역시 고려해야 할 것이다.
또한 머신러닝 모델의 추론의 도출 과정을 머신러닝 비전문가에게 설명할 때는 추론의 정확도만큼 추론 과정의 시각화가 중요할 것이다.

아래의 표는 머신러닝 알고리즘의 장단점 비교이다.
---------------------------------------------------------------------------------------------------------------------------------
알고리즘         장점                                        단점
k-최근접 이웃    - 구현이 쉽다.                              - 예측 속도가 느리다.
                 - 알고리즘을 이해하기 쉽다.                 - 메모리를 많이 쓴다.
                 - 하이퍼파라미터가 적다.                    - 노이즈 데이터에 예민하다.
---------------------------------------------------------------------------------------------------------------------------------
서포트 벡터 머신  - 상대적으로 적은 데이터로도                - 결정경계선이 많이 겹칠 때 정확도가 낮아진다.
                    높은 정확도를 낸다.                      - 수학적 이해 없이는 모델의 분류 결과를 이해하기 어렵다.
                  - 예측 속도가 빠르다.                      - 커널 트릭 오사용 시 과대적합되기 쉽다.
                  - 고차원 데이터를 처리하기가 쉽다.
---------------------------------------------------------------------------------------------------------------------------------
의사결정트리       - 모델의 추론 과정을 시각화하기 쉽다.      - 과대적합되게 쉽다.
                  - 데이터에서 중요한 특성이 무엇인지 쉽게    - 조정해야 할 하이퍼파라미터가 많다.
                    알아낼 수 있다.
                  - 학습 및 예측 속도가 빠르다.
---------------------------------------------------------------------------------------------------------------------------------        
랜덤포레스트      - 앙상블 효과로 의사결정 트리의 과대적합     - 조정해야 할 하이퍼파라미터가 많다.
                    단점을 보완한다.
---------------------------------------------------------------------------------------------------------------------------------
나이브베이즈      - 고차원 데이터를 처리하기가 쉽다.           - 모든 변수가 독립변수라는 가설하에 작동
                  - 구현하기 쉽다.                              함으로써 데이터가 가설과 다른 경우 정확도가 낮아진다.
                  - 학습 및 추론시간이 빠르다.
---------------------------------------------------------------------------------------------------------------------------------
선형회귀          - 수집된 데이터를 통해 새롭게 관측된         - 데이터 특징들이 선형 관계에 있다는 가설하에 작동함으로써 
                    데이터의 예측값(수치값)을 구할 수 있다.      데이터 특징이 가설과 다를 경우 정확도가 낮아진다.
---------------------------------------------------------------------------------------------------------------------------------
로지스틱회귀      - 데이터를 분류할 때 확률을 제공한다.        - 데이터 특징이 많을 경우 학습이 어려워 과소적합되게 쉽다.
---------------------------------------------------------------------------------------------------------------------------------
K 평균            - 데이터 크기에 상관 없이 군집화에 사용      - 군집화 결과에 대한 확률을 제공하지 않는다.
                    할 수 있다.                               - 데이터의 분포가 균일하지 않을 경우 정확도가 떨어진다.
                  - 구현하기 쉽다.
---------------------------------------------------------------------------------------------------------------------------------
주성분 분석        - 고차원 데이터를 저차원 데이터로 축소      - 차원 축소 시 정보의 손실이 있다.
                     할 때 사용된다.
                   - 구현이 쉽다.
---------------------------------------------------------------------------------------------------------------------------------
